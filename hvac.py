# -*- coding: utf-8 -*-
"""HVAC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JPJA8QoBr5ZRUB9ja4iph8xnAMuvM82H
"""

import pandas as pd
import numpy as np
sec_30 = pd.read_csv("C:/Users/subhash/OneDrive/Desktop/final30.csv")

sec_30

X = sec_30[['temp','hum','CO2']]
y = sec_30["occupancy_level"]

column_names=["temp","hum","occ","CO2","occupancy_level"]
def createdataset(data):
    test = pd.DataFrame(columns = column_names)
    train = pd.DataFrame(columns = column_names)
    curr=1
    key = 0
    while(curr<=len(data)):
        print(curr)
        if(key==0):
            if(curr+60>len(data)):
                train = train.append(data[curr:])
            else:
                train = train.append(data[curr:curr+60])
            key=1
            curr+=60
        else:
            if(curr+20>len(data)):
                test = test.append(data[curr:])
            else:
                test = test.append(data[curr:curr+20])
            curr+=20
            key=0
    return train,test

data1_train,data1_test = createdataset(sec_30)

data1_train["occ"] = data1_train["occ"].astype(int)
data1_train["occupancy_level"] = data1_train["occupancy_level"].astype(int)

data1_test["occ"] = data1_test["occ"].astype(int)
data1_test["occupancy_level"] = data1_test["occupancy_level"].astype(int)

data1_test.occupancy_level.value_counts()

data1_train.occupancy_level.value_counts()

data1_train.corr()

data1_test.corr()

x_columns = ["hum","CO2","temp"]
y_columns = ["occ"]

X_train,X_test = data1_train[x_columns].to_numpy() , data1_test[x_columns].to_numpy()
y_train,y_test = data1_train["occupancy_level"] , data1_test["occupancy_level"]

y_train = y_train.astype(int)
y_test = y_test.astype(int)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""## KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=22)
knn.fit(X_train, y_train)
knn.score(X_train, y_train)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# Print the 10-fold cross-validation scores
cv_scores = cross_val_score(knn, X_train, y_train, cv=10,scoring='accuracy')
print(cv_scores)
print('Average 10-Fold CV Score: {:.4f}'.format(np.mean(cv_scores)))

knn.fit(X_train,y_train) #learning
#prediciton
print("knn Score: ",knn.score(X_test,y_test))
knnscore = knn.score(X_test,y_test)

knn.score(X_test,y_test)

y_pred = knn.predict(X_test)

from sklearn.metrics import classification_report
from sklearn import metrics

# Predict the labels of the test set: y_pred
y_pred = knn.predict(X_test)

# Compute and print the classification report and training and test scores
print('kNN Classification Report: \n{}'.format(classification_report(y_test, y_pred)))
print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))
print('Accuracy {:.4f}'.format(metrics.accuracy_score(y_test, y_pred)))
print('F1-score ',metrics.f1_score(y_test, y_pred, average='weighted'))

from sklearn import metrics
k_range = range(1, 40)

# We can create Python dictionary using [] or dict()
scores = []

# We use a loop through the range 1 to 26
# We append the scores in the dictionary
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))

print(scores)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# allow plots to appear within the notebook
# %matplotlib inline
# plot the relationship between K and testing accuracy
# plt.plot(x_axis, y_axis)
plt.plot(k_range, scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

yprediciton2= knn.predict(X_test)
ytrue = y_test

from sklearn.metrics import confusion_matrix
CM = confusion_matrix(y_test,yprediciton2)

#CM visualization

import seaborn as sns
import matplotlib.pyplot as plt

f, ax = plt.subplots(figsize=(7,5))
sns.heatmap(CM,annot = True, linewidths=1,linecolor="white",fmt=".0f",ax=ax)
plt.xlabel("Prediction(Ypred)")
plt.ylabel("Ytrue")
plt.show()

"""## SVM"""

from sklearn.svm import SVC

SVM = SVC(random_state=42)

from sklearn.model_selection import cross_val_score
accuraccies = cross_val_score(estimator = SVM, X= X_train, y=y_train, cv=10)
print("Average Accuracies: ",np.mean(accuraccies))
print("Standart Deviation Accuracies: ",np.std(accuraccies))

SVM.fit(X_train,y_train)  #learning 
#SVM Test 
print ("SVM Accuracy:", SVM.score(X_test,y_test))

SVMscore = SVM.score(X_test,y_test)

y_pred = SVM.predict(X_test)
print('Accuracy {:.4f}'.format(metrics.accuracy_score(y_test, y_pred)))
print('F1-score ',metrics.f1_score(y_test, y_pred, average='weighted'))

"""### Hyperparameter Tuning"""

# Scale and tune hyperparameters using a SVM classifer
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import RobustScaler

pipe = Pipeline([('scaler', RobustScaler()),
                 ('clf', SVC())])

# Specify the hyperparameter space
param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.00]

param_grid = [{'clf__kernel': ['linear'], 'clf__C': param_range,
               'clf__class_weight': [None, 'balanced']},
              {'clf__kernel': ['rbf'], 'clf__C': param_range,
               'clf__class_weight': [None, 'balanced'], 'clf__gamma': param_range}]
      
# Instantiate the GridSearchCV object: svc
grid = GridSearchCV(pipe, param_grid, cv=10)

# Fit to the training set
svm = grid.fit(X_train, y_train)

print('Best Estimator:\n{}'.format(svm.best_estimator_))

print('SVM Model')
print('Best Score: {:.4f}'.format(svm.best_score_))
print('Best Parameters: {}'.format(svm.best_params_))

"""## Decision Trees"""

from sklearn.tree import DecisionTreeClassifier
DTC = DecisionTreeClassifier()

from sklearn.model_selection import cross_val_score
accuraccies = cross_val_score(estimator = DTC, X= X_train, y=y_train, cv=10)
print("Average Accuracies: ",np.mean(accuraccies))
print("Standart Deviation Accuracies: ",np.std(accuraccies))

DTC.fit(X_train,y_train) #learning
#prediciton
print("Decision Tree Score: ",DTC.score(X_test,y_test))
DTCscore = DTC.score(X_test,y_test)

max_depth_range = list(range(1, 10))# List to store the average RMSE for each value of max_depth:
accuracy = []
for depth in max_depth_range:
    
    clf = DecisionTreeClassifier(max_depth = depth, 
                             random_state = 0)
    clf.fit(X_train, y_train)    
    score = clf.score(X_test, y_test)
    accuracy.append(score)
print(accuracy)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# allow plots to appear within the notebook
# %matplotlib inline
# plot the relationship between K and testing accuracy
# plt.plot(x_axis, y_axis)
plt.plot(max_depth_range, accuracy)
plt.xlabel('Value of depth for DT')
plt.ylabel('Testing Accuracy')

y_pred = DTC.predict(X_test)
print('Accuracy {:.4f}'.format(metrics.accuracy_score(y_test, y_pred)))
print('F1-score ',metrics.f1_score(y_test, y_pred,average = 'weighted'))

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
RFC= RandomForestClassifier( random_state=42)

from sklearn.model_selection import cross_val_score
accuraccies = cross_val_score(estimator = RFC, X= X_train, y=y_train, cv=10)
print("Average Accuracies: ",np.mean(accuraccies))
print("Standart Deviation Accuracies: ",np.std(accuraccies))

RFC.fit(X_train,y_train) # learning
print("Random Forest Score: ",RFC.score(X_test,y_test))
RFCscore=RFC.score(X_test,y_test)

y_pred = RFC.predict(X_test)
print('Accuracy {:.4f}'.format(metrics.accuracy_score(y_test, y_pred)))
print('F1-score ',metrics.f1_score(y_test, y_pred,average = 'weighted'))

scores = []
for each in range(80,100):
    RFfind = RandomForestClassifier(n_estimators = each)
    RFfind.fit(X_train,y_train)
    scores.append(RFfind.score(X_test,y_test))
    
plt.figure(1, figsize=(10, 5))
plt.plot(range(80,100),scores,color="black",linewidth=2)
plt.title("Optimum N Estimator Value")
plt.xlabel("N Estimators")
plt.ylabel("Score(Accuracy)")
plt.grid(True)
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score

# Fit GaussianNB classifier onto the training data: bayes
bayes = GaussianNB().fit(X_train, y_train)

cv_scores = cross_val_score(bayes, X_train, y_train, cv=10)

print('GaussianNB Cross-Validation Scores')
print(cv_scores)
print('Average 12-Fold CV Score: {:.4f}'.format(np.mean(cv_scores)))

from sklearn.metrics import classification_report

# Predict test set labels: y_pred
y_pred = bayes.predict(X_test)

print('Naive Bayes Classification Report')
print(classification_report(y_test, y_pred))
print('Training set score: {:.4f}'.format(bayes.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(bayes.score(X_test, y_test)))

"""### Knn performed better"""

X_test[0]

import time
for i in range(len(X_test)):
    print("predicted value :",knn.predict([X_test[i]])[0], end = " ")
    print("Actual Value    :",y_test.iloc[i])

